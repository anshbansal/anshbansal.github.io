{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lesson 1: Data Extraction Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 - Intro\n",
    "- Data Scientists spend about 70% of time data wrangling\n",
    "- data Wrangling is process of gathering, extracting, cleaning and storing our data\n",
    "- need to make sure that data is in good shape before doing any analysis\n",
    "- otherwise\n",
    "    - waste lot of time\n",
    "    - lose the faith of your colleagues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 - Assessing the Quality of Data Pt 1\n",
    "- We should not trust any data as we get data\n",
    "    - entered by a human\n",
    "    - created by a program written by a human"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 - Assessing the Quality of Data Pt 2\n",
    "\n",
    "We need to assess our data to\n",
    "- Test assumptions about\n",
    "    - values\n",
    "    - data types\n",
    "    - shape\n",
    "- identify errors or outliers\n",
    "- find missing values\n",
    "- ensure that our data will support the type of queries that we need it to make\n",
    "- Eliminate any surprises later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 - Tabular Format\n",
    "\n",
    "![](tabular.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06 - CSV Format\n",
    "\n",
    "CSV is lighweight\n",
    "- Each line of text is a single row\n",
    "- Fields are separated by delimiter\n",
    "- stores just the data itself\n",
    "- don't need special purpose software\n",
    "- all spreadsheet software read/write CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07 - Parsing CSV Files in Python\n",
    "- not all spreadsheet software can handle big files\n",
    "- reading in csv in case the number of files is big manually is not an option\n",
    "\n",
    "We will try and parse a CSV file as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_FILE_CSV = \"beatles-diskography.csv\"\n",
    "\n",
    "def parse_file(data_file):\n",
    "    data = []\n",
    "    row_count = 0\n",
    "    with open(data_file) as f:\n",
    "        header = f.readline().split(',')\n",
    "        for line in f:\n",
    "            if row_count >= 10:\n",
    "                break\n",
    "                \n",
    "            fields = line.strip().split(',')\n",
    "            \n",
    "            row = {}\n",
    "            for i, value in enumerate(fields):\n",
    "                row[header[i].strip()] = value.strip()\n",
    "                \n",
    "            data.append(row)\n",
    "            \n",
    "            row_count += 1\n",
    "            \n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BPI Certification': 'Gold',\n",
       " 'Label': 'Parlophone(UK)',\n",
       " 'RIAA Certification': 'Platinum',\n",
       " 'Released': '22 March 1963',\n",
       " 'Title': 'Please Please Me',\n",
       " 'UK Chart Position': '1',\n",
       " 'US Chart Position': '\\xe2\\x80\\x94'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = parse_file(DATA_FILE_CSV)\n",
    "\n",
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(data):\n",
    "    assert data[0] == {'BPI Certification': 'Gold',\n",
    "      'Label': 'Parlophone(UK)',\n",
    "      'RIAA Certification': 'Platinum',\n",
    "      'Released': '22 March 1963',\n",
    "      'Title': 'Please Please Me',\n",
    "      'UK Chart Position': '1',\n",
    "      'US Chart Position': '\\xe2\\x80\\x94'}\n",
    "\n",
    "    assert data[9] == {'BPI Certification': 'Gold',\n",
    "     'Label': 'Parlophone(UK)',\n",
    "     'RIAA Certification': '',\n",
    "     'Released': '10 July 1964',\n",
    "     'Title': '',\n",
    "     'UK Chart Position': '1',\n",
    "     'US Chart Position': '\\xe2\\x80\\x94'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 - Using CSV Module\n",
    "\n",
    "But there are many small things that will cause us problems if we try and write the CSV reader by ourselves. So we will re write the above using python's [csv](http://docs.python.org/2/library/csv.html) module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def parse_csv(data_file):\n",
    "    data = []\n",
    "    with open(data_file, 'rb') as sd:\n",
    "        r = csv.DictReader(sd)\n",
    "        for line in r:\n",
    "            data.append(line)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test(parse_csv(DATA_FILE_CSV))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 - Intro to XLRD\n",
    "\n",
    "This module allows us to work with Excel documents whether it is the old `.xls` or the new `.xlsx` format\n",
    "\n",
    "We can install `xlrd` using\n",
    "\n",
    "`pip install xlrd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_sheet(sheet):\n",
    "    return [[sheet.cell_value(r, col) \n",
    "                for col in range(sheet.ncols)] \n",
    "                    for r in range(sheet.nrows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "\n",
    "DATA_FILE_EXCEL = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "\n",
    "def parse_excel_file(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "    data = read_sheet(sheet)\n",
    "\n",
    "    print \"\\nList Comprehension\"\n",
    "    print \"data[3][2]:\",\n",
    "    print data[3][2]\n",
    "\n",
    "    print \"\\nCells in a nested loop:\"    \n",
    "    for row in range(sheet.nrows):\n",
    "        for col in range(sheet.ncols):\n",
    "            if row == 50:\n",
    "                print sheet.cell_value(row, col),\n",
    "\n",
    "\n",
    "    ### other useful methods:\n",
    "    print \"\\nROWS, COLUMNS, and CELLS:\"\n",
    "    print \"Number of rows in the sheet:\", \n",
    "    print sheet.nrows\n",
    "    print \"Type of data in cell (row 3, col 2):\", \n",
    "    print sheet.cell_type(3, 2)\n",
    "    print \"Value in cell (row 3, col 2):\", \n",
    "    print sheet.cell_value(3, 2)\n",
    "    print \"Get a slice of values in column 3, from rows 1-3:\"\n",
    "    print sheet.col_values(3, start_rowx=1, end_rowx=4)\n",
    "\n",
    "    print \"\\nDATES:\"\n",
    "    print \"Type of data in cell (row 1, col 0):\", \n",
    "    print sheet.cell_type(1, 0)\n",
    "    exceltime = sheet.cell_value(1, 0)\n",
    "    print \"Time in Excel format:\",\n",
    "    print exceltime\n",
    "    print \"Convert time to a Python datetime tuple, from the Excel float:\",\n",
    "    print xlrd.xldate_as_tuple(exceltime, 0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List Comprehension\n",
      "data[3][2]: 1036.088697\n",
      "\n",
      "Cells in a nested loop:\n",
      "41277.0833333 9238.73731 1438.20528 1565.442856 916.708348 14010.903488 3027.98334 6165.211119 1157.741663 37520.933404 \n",
      "ROWS, COLUMNS, and CELLS:\n",
      "Number of rows in the sheet: 7296\n",
      "Type of data in cell (row 3, col 2): 2\n",
      "Value in cell (row 3, col 2): 1036.088697\n",
      "Get a slice of values in column 3, from rows 1-3:\n",
      "[1411.7505669999982, 1403.4722870000019, 1395.053150000001]\n",
      "\n",
      "DATES:\n",
      "Type of data in cell (row 1, col 0): 3\n",
      "Time in Excel format: 41275.0416667\n",
      "Convert time to a Python datetime tuple, from the Excel float: (2013, 1, 1, 1, 0, 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[u'Hour_End',\n",
       "  u'COAST',\n",
       "  u'EAST',\n",
       "  u'FAR_WEST',\n",
       "  u'NORTH',\n",
       "  u'NORTH_C',\n",
       "  u'SOUTHERN',\n",
       "  u'SOUTH_C',\n",
       "  u'WEST',\n",
       "  u'ERCOT'],\n",
       " [41275.041666666664,\n",
       "  7606.263544000012,\n",
       "  1073.892438,\n",
       "  1411.7505669999982,\n",
       "  784.9781659999992,\n",
       "  10369.094390000051,\n",
       "  2206.6750770000012,\n",
       "  4368.490945000006,\n",
       "  882.9319009999975,\n",
       "  28704.077028000065]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = parse_excel_file(DATA_FILE_EXCEL)\n",
    "\n",
    "data[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 - Reading Excel Files\n",
    "\n",
    "- Read the ERCOT load excel file\n",
    "- Find min., max. and avg. for COAST and report timestamp (Hour_End) for min. and max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_for_column(sheet, column_index):\n",
    "    return sheet.col_values(column_index, start_rowx=1, end_rowx=None)\n",
    "\n",
    "def row_index_for_value_in_column(data, value):\n",
    "    return data.index(value) + 1\n",
    "\n",
    "def cell_value_at_position(sheet, row, col):\n",
    "    return sheet.cell_value(row, col)\n",
    "\n",
    "def parse_excel_date(excel_date):\n",
    "    return xlrd.xldate_as_tuple(excel_date, 0)\n",
    "\n",
    "def get_date_for_row_containing_value(sheet, column_data, value):\n",
    "    index = row_index_for_value_in_column(column_data, value)\n",
    "    date = cell_value_at_position(sheet, index, 0)\n",
    "    result = parse_excel_date(date)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_file_13(datafile):\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "    sheet_data = read_sheet(sheet)\n",
    "    \n",
    "    cv = data_for_column(sheet, 1)\n",
    "    max_data = max(cv)\n",
    "    min_data = min(cv)\n",
    "    \n",
    "    \n",
    "    #print sheet_data\n",
    "    data = {\n",
    "            'maxtime': get_date_for_row_containing_value(sheet, cv, max_data),\n",
    "            'maxvalue': max_data,\n",
    "            'mintime': get_date_for_row_containing_value(sheet, cv, min_data),\n",
    "            'minvalue': min_data,\n",
    "            'avgcoast': sum(cv) / float(len(cv))\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avgcoast': 10976.933460679751,\n",
      " 'maxtime': (2013, 8, 13, 17, 0, 0),\n",
      " 'maxvalue': 18779.025510000003,\n",
      " 'mintime': (2013, 2, 3, 4, 0, 0),\n",
      " 'minvalue': 6602.113898999982}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "data = parse_file_13(DATA_FILE_EXCEL)\n",
    "\n",
    "pprint.pprint(data)\n",
    "\n",
    "assert data['maxtime'] == (2013, 8, 13, 17, 0, 0)\n",
    "assert round(data['maxvalue'], 10) == round(18779.02551, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 - Intro to JSON\n",
    "- sometimes fields have nested fields\n",
    "- sometimes items may have different fields. sometimes optional\n",
    "\n",
    "#### Resources\n",
    "- [JSON Tutorial](http://www.w3schools.com/json/)\n",
    "- http://www.json.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17 - JSON Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "BASE_URL = \"http://musicbrainz.org/ws/2/\"\n",
    "ARTIST_URL = BASE_URL + \"artist/\"\n",
    "\n",
    "# query parameters are given to the requests.get function as a dictionary; this\n",
    "# variable contains some starter parameters.\n",
    "query_type = {  \"simple\": {},\n",
    "                \"atr\": {\"inc\": \"aliases+tags+ratings\"},\n",
    "                \"aliases\": {\"inc\": \"aliases\"},\n",
    "                \"releases\": {\"inc\": \"releases\"}}\n",
    "\n",
    "def query_site(url, params, uid=\"\", fmt=\"json\"):\n",
    "    # This is the main function for making queries to the musicbrainz API.\n",
    "    # A json document should be returned by the query.\n",
    "    params[\"fmt\"] = fmt\n",
    "    r = requests.get(url + uid, params=params)\n",
    "    print \"requesting\", r.url\n",
    "\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        return r.json()\n",
    "    else:\n",
    "        r.raise_for_status()\n",
    "\n",
    "\n",
    "def query_by_name(url, params, name):\n",
    "    # This adds an artist name to the query parameters before making\n",
    "    # an API call to the function above.\n",
    "    params[\"query\"] = \"artist:\" + name\n",
    "    return query_site(url, params)\n",
    "\n",
    "\n",
    "def pretty_print(data, indent=4):\n",
    "    # After we get our output, we can format it to be more readable\n",
    "    # by using this function.\n",
    "    if type(data) == dict:\n",
    "        print json.dumps(data, indent=indent, sort_keys=True)\n",
    "    else:\n",
    "        print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def json_play():\n",
    "    '''\n",
    "    Modify the function calls and indexing below to answer the questions on\n",
    "    the next quiz. HINT: Note how the output we get from the site is a\n",
    "    multi-level JSON document, so try making print statements to step through\n",
    "    the structure one level at a time or copy the output to a separate output\n",
    "    file.\n",
    "    '''\n",
    "    results = query_by_name(ARTIST_URL, query_type[\"simple\"], \"Nirvana\")\n",
    "    print \"All Results for Nirvana\"\n",
    "    pretty_print(results)\n",
    "\n",
    "    artist_id = results[\"artists\"][1][\"id\"]\n",
    "    print \"\\nARTIST:\"\n",
    "    pretty_print(results[\"artists\"][1])\n",
    "\n",
    "    artist_data = query_site(ARTIST_URL, query_type[\"releases\"], artist_id)\n",
    "    releases = artist_data[\"releases\"]\n",
    "    print \"\\nONE RELEASE:\"\n",
    "    pretty_print(releases[0], indent=2)\n",
    "    release_titles = [r[\"title\"] for r in releases]\n",
    "\n",
    "    print \"\\nALL TITLES:\"\n",
    "    for t in release_titles:\n",
    "        print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3ANirvana&fmt=json\n",
      "All Results for Nirvana\n",
      "{\n",
      "    \"artists\": [\n",
      "        {\n",
      "            \"aliases\": [\n",
      "                {\n",
      "                    \"begin-date\": null, \n",
      "                    \"end-date\": null, \n",
      "                    \"locale\": null, \n",
      "                    \"name\": \"Nirvana US\", \n",
      "                    \"primary\": null, \n",
      "                    \"sort-name\": \"Nirvana US\", \n",
      "                    \"type\": null\n",
      "                }\n",
      "            ], \n",
      "            \"area\": {\n",
      "                \"id\": \"489ce91b-6658-3307-9877-795b68554c98\", \n",
      "                \"name\": \"United States\", \n",
      "                \"sort-name\": \"United States\"\n",
      "            }, \n",
      "            \"begin-area\": {\n",
      "                \"id\": \"a640b45c-c173-49b1-8030-973603e895b5\", \n",
      "                \"name\": \"Aberdeen\", \n",
      "                \"sort-name\": \"Aberdeen\"\n",
      "            }, \n",
      "            \"country\": \"US\", \n",
      "            \"disambiguation\": \"90s US grunge band\", \n",
      "            \"id\": \"5b11f4ce-a62d-471e-81fc-a69a8278c7da\", \n",
      "            \"life-span\": {\n",
      "                \"begin\": \"1988-01\", \n",
      "                \"end\": \"1994-04-05\", \n",
      "                \"ended\": true\n",
      "            }, \n",
      "            \"name\": \"Nirvana\", \n",
      "            \"score\": \"100\", \n",
      "            \"sort-name\": \"Nirvana\", \n",
      "            \"tags\": [\n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"punk\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 0, \n",
      "                    \"name\": \"legendary\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 0, \n",
      "                    \"name\": \"90\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"seattle\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 0, \n",
      "                    \"name\": \"northwest\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 0, \n",
      "                    \"name\": \"alternative\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 0, \n",
      "                    \"name\": \"rock and indie\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"usa\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 0, \n",
      "                    \"name\": \"am\\u00e9ricain\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 0, \n",
      "                    \"name\": \"united states\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 0, \n",
      "                    \"name\": \"kurt cobain\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"90s\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 4, \n",
      "                    \"name\": \"alternative rock\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 0, \n",
      "                    \"name\": \"band\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 13, \n",
      "                    \"name\": \"grunge\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 9, \n",
      "                    \"name\": \"rock\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"acoustic rock\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"noise rock\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 0, \n",
      "                    \"name\": \"nirvana\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 5, \n",
      "                    \"name\": \"american\"\n",
      "                }\n",
      "            ], \n",
      "            \"type\": \"Group\"\n",
      "        }, \n",
      "        {\n",
      "            \"area\": {\n",
      "                \"id\": \"8a754a16-0027-3a29-b6d7-2b40ea0481ed\", \n",
      "                \"name\": \"United Kingdom\", \n",
      "                \"sort-name\": \"United Kingdom\"\n",
      "            }, \n",
      "            \"begin-area\": {\n",
      "                \"id\": \"f03d09b3-39dc-4083-afd6-159e3f0d462f\", \n",
      "                \"name\": \"London\", \n",
      "                \"sort-name\": \"London\"\n",
      "            }, \n",
      "            \"country\": \"GB\", \n",
      "            \"disambiguation\": \"60s band from the UK\", \n",
      "            \"id\": \"9282c8b4-ca0b-4c6b-b7e3-4f7762dfc4d6\", \n",
      "            \"life-span\": {\n",
      "                \"begin\": \"1967\", \n",
      "                \"ended\": null\n",
      "            }, \n",
      "            \"name\": \"Nirvana\", \n",
      "            \"score\": \"100\", \n",
      "            \"sort-name\": \"Nirvana\", \n",
      "            \"tags\": [\n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"rock\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"pop\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"progressive rock\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"orchestral\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"british\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"power pop\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"psychedelic rock\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"soft rock\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"symphonic rock\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"english\"\n",
      "                }\n",
      "            ], \n",
      "            \"type\": \"Group\"\n",
      "        }, \n",
      "        {\n",
      "            \"area\": {\n",
      "                \"id\": \"6a264f94-6ff1-30b1-9a81-41f7bfabd616\", \n",
      "                \"name\": \"Finland\", \n",
      "                \"sort-name\": \"Finland\"\n",
      "            }, \n",
      "            \"country\": \"FI\", \n",
      "            \"disambiguation\": \"Early 1980's Finnish punk band\", \n",
      "            \"id\": \"85af0709-95db-4fbc-801a-120e9f4766d0\", \n",
      "            \"life-span\": {\n",
      "                \"ended\": null\n",
      "            }, \n",
      "            \"name\": \"Nirvana\", \n",
      "            \"score\": \"100\", \n",
      "            \"sort-name\": \"Nirvana\", \n",
      "            \"tags\": [\n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"punk\"\n",
      "                }, \n",
      "                {\n",
      "                    \"count\": 1, \n",
      "                    \"name\": \"finland\"\n",
      "                }\n",
      "            ], \n",
      "            \"type\": \"Group\"\n",
      "        }, \n",
      "        {\n",
      "            \"disambiguation\": \"founded in 1987 by a Michael Jackson double/imitator\", \n",
      "            \"id\": \"3aa878c0-224b-41e5-abd1-63be359d2bca\", \n",
      "            \"life-span\": {\n",
      "                \"begin\": \"1987\", \n",
      "                \"ended\": null\n",
      "            }, \n",
      "            \"name\": \"Nirvana\", \n",
      "            \"score\": \"100\", \n",
      "            \"sort-name\": \"Nirvana\"\n",
      "        }, \n",
      "        {\n",
      "            \"disambiguation\": \"French band from Martigues, activ during the 70s.\", \n",
      "            \"id\": \"c49d69dc-e008-47cf-b5ff-160fafb1fe1f\", \n",
      "            \"life-span\": {\n",
      "                \"ended\": null\n",
      "            }, \n",
      "            \"name\": \"Nirvana\", \n",
      "            \"score\": \"100\", \n",
      "            \"sort-name\": \"Nirvana\"\n",
      "        }, \n",
      "        {\n",
      "            \"id\": \"b305320e-c158-43f4-b5be-4450e2f99a32\", \n",
      "            \"life-span\": {\n",
      "                \"ended\": null\n",
      "            }, \n",
      "            \"name\": \"El Nirvana\", \n",
      "            \"score\": \"62\", \n",
      "            \"sort-name\": \"Nirvana, El\"\n",
      "        }, \n",
      "        {\n",
      "            \"aliases\": [\n",
      "                {\n",
      "                    \"begin-date\": null, \n",
      "                    \"end-date\": null, \n",
      "                    \"locale\": null, \n",
      "                    \"name\": \"Nirvana\", \n",
      "                    \"primary\": null, \n",
      "                    \"sort-name\": \"Nirvana\", \n",
      "                    \"type\": null\n",
      "                }, \n",
      "                {\n",
      "                    \"begin-date\": null, \n",
      "                    \"end-date\": null, \n",
      "                    \"locale\": null, \n",
      "                    \"name\": \"Prophet 2002\", \n",
      "                    \"primary\": null, \n",
      "                    \"sort-name\": \"Prophet 2002\", \n",
      "                    \"type\": null\n",
      "                }\n",
      "            ], \n",
      "            \"area\": {\n",
      "                \"id\": \"23d10872-f5ae-3f0c-bf55-332788a16ecb\", \n",
      "                \"name\": \"Sweden\", \n",
      "                \"sort-name\": \"Sweden\"\n",
      "            }, \n",
      "            \"country\": \"SE\", \n",
      "            \"disambiguation\": \"Swedish death metal band\", \n",
      "            \"id\": \"f2dfdff9-3862-4be0-bf85-9c833fa3059e\", \n",
      "            \"life-span\": {\n",
      "                \"begin\": \"1988\", \n",
      "                \"ended\": null\n",
      "            }, \n",
      "            \"name\": \"Nirvana 2002\", \n",
      "            \"score\": \"62\", \n",
      "            \"sort-name\": \"Nirvana 2002\", \n",
      "            \"type\": \"Group\"\n",
      "        }, \n",
      "        {\n",
      "            \"id\": \"329c04ae-3b73-4ca3-996f-75608ab1befb\", \n",
      "            \"life-span\": {\n",
      "                \"ended\": null\n",
      "            }, \n",
      "            \"name\": \"Nirvana Singh\", \n",
      "            \"score\": \"62\", \n",
      "            \"sort-name\": \"Singh, Nirvana\", \n",
      "            \"type\": \"Person\"\n",
      "        }, \n",
      "        {\n",
      "            \"area\": {\n",
      "                \"id\": \"489ce91b-6658-3307-9877-795b68554c98\", \n",
      "                \"name\": \"United States\", \n",
      "                \"sort-name\": \"United States\"\n",
      "            }, \n",
      "            \"country\": \"US\", \n",
      "            \"id\": \"c3a64a25-251b-4d03-afba-1471440245b8\", \n",
      "            \"life-span\": {\n",
      "                \"begin\": \"2009\", \n",
      "                \"ended\": null\n",
      "            }, \n",
      "            \"name\": \"Approaching Nirvana\", \n",
      "            \"score\": \"62\", \n",
      "            \"sort-name\": \"Approaching Nirvana\", \n",
      "            \"type\": \"Group\"\n",
      "        }, \n",
      "        {\n",
      "            \"area\": {\n",
      "                \"id\": \"489ce91b-6658-3307-9877-795b68554c98\", \n",
      "                \"name\": \"United States\", \n",
      "                \"sort-name\": \"United States\"\n",
      "            }, \n",
      "            \"country\": \"US\", \n",
      "            \"gender\": \"female\", \n",
      "            \"id\": \"206419e0-3a7a-49ce-8437-4e757767d02b\", \n",
      "            \"life-span\": {\n",
      "                \"ended\": null\n",
      "            }, \n",
      "            \"name\": \"Nirvana Savoury\", \n",
      "            \"score\": \"62\", \n",
      "            \"sort-name\": \"Savoury, Nirvana\", \n",
      "            \"type\": \"Person\"\n",
      "        }, \n",
      "        {\n",
      "            \"id\": \"86f9ae24-ba2a-4d55-9275-0b89b85f6e3a\", \n",
      "            \"life-span\": {\n",
      "                \"ended\": null\n",
      "            }, \n",
      "            \"name\": \"Weed Nirvana\", \n",
      "            \"score\": \"62\", \n",
      "            \"sort-name\": \"Weed Nirvana\"\n",
      "        }, \n",
      "        {\n",
      "            \"area\": {\n",
      "                \"id\": \"e8ad73e9-9e7f-41c4-a395-6e29260ff1df\", \n",
      "                \"name\": \"Graz\", \n",
      "                \"sort-name\": \"Graz\"\n",
      "            }, \n",
      "            \"begin-area\": {\n",
      "                \"id\": \"e8ad73e9-9e7f-41c4-a395-6e29260ff1df\", \n",
      "                \"name\": \"Graz\", \n",
      "                \"sort-name\": \"Graz\"\n",
      "            }, \n",
      "            \"disambiguation\": \"Nirvana-Coverband\", \n",
      "            \"id\": \"46d8dae4-abec-438b-9c62-a3dbb2aaa1b7\", \n",
      "            \"life-span\": {\n",
      "                \"begin\": \"2000\", \n",
      "                \"ended\": null\n",
      "            }, \n",
      "            \"name\": \"Nirvana Teen Spirit\", \n",
      "            \"score\": \"50\", \n",
      "            \"sort-name\": \"Nirvana Teen Spirit\", \n",
      "            \"type\": \"Group\"\n",
      "        }, \n",
      "        {\n",
      "            \"area\": {\n",
      "                \"id\": \"c621114d-73cc-4832-8afe-f13dc261e5af\", \n",
      "                \"name\": \"Gatineau\", \n",
      "                \"sort-name\": \"Gatineau\"\n",
      "            }, \n",
      "            \"begin-area\": {\n",
      "                \"id\": \"c621114d-73cc-4832-8afe-f13dc261e5af\", \n",
      "                \"name\": \"Gatineau\", \n",
      "                \"sort-name\": \"Gatineau\"\n",
      "            }, \n",
      "            \"id\": \"02c4e6bb-7b7a-4686-8c23-df01bfd42b0e\", \n",
      "            \"life-span\": {\n",
      "                \"begin\": \"2012-04-05\", \n",
      "                \"ended\": null\n",
      "            }, \n",
      "            \"name\": \"Sappy Nirvana Tribute\", \n",
      "            \"score\": \"50\", \n",
      "            \"sort-name\": \"Sappy Nirvana Tribute\", \n",
      "            \"type\": \"Group\"\n",
      "        }, \n",
      "        {\n",
      "            \"id\": \"e1388435-f80d-434a-9980-f1c9f5aa9b90\", \n",
      "            \"life-span\": {\n",
      "                \"ended\": null\n",
      "            }, \n",
      "            \"name\": \"Nirvana Sitar & String Group\", \n",
      "            \"score\": \"43\", \n",
      "            \"sort-name\": \"Nirvana Sitar & String Group\"\n",
      "        }\n",
      "    ], \n",
      "    \"count\": 14, \n",
      "    \"created\": \"2016-08-19T13:37:44.018Z\", \n",
      "    \"offset\": 0\n",
      "}\n",
      "\n",
      "ARTIST:\n",
      "{\n",
      "    \"area\": {\n",
      "        \"id\": \"8a754a16-0027-3a29-b6d7-2b40ea0481ed\", \n",
      "        \"name\": \"United Kingdom\", \n",
      "        \"sort-name\": \"United Kingdom\"\n",
      "    }, \n",
      "    \"begin-area\": {\n",
      "        \"id\": \"f03d09b3-39dc-4083-afd6-159e3f0d462f\", \n",
      "        \"name\": \"London\", \n",
      "        \"sort-name\": \"London\"\n",
      "    }, \n",
      "    \"country\": \"GB\", \n",
      "    \"disambiguation\": \"60s band from the UK\", \n",
      "    \"id\": \"9282c8b4-ca0b-4c6b-b7e3-4f7762dfc4d6\", \n",
      "    \"life-span\": {\n",
      "        \"begin\": \"1967\", \n",
      "        \"ended\": null\n",
      "    }, \n",
      "    \"name\": \"Nirvana\", \n",
      "    \"score\": \"100\", \n",
      "    \"sort-name\": \"Nirvana\", \n",
      "    \"tags\": [\n",
      "        {\n",
      "            \"count\": 1, \n",
      "            \"name\": \"rock\"\n",
      "        }, \n",
      "        {\n",
      "            \"count\": 1, \n",
      "            \"name\": \"pop\"\n",
      "        }, \n",
      "        {\n",
      "            \"count\": 1, \n",
      "            \"name\": \"progressive rock\"\n",
      "        }, \n",
      "        {\n",
      "            \"count\": 1, \n",
      "            \"name\": \"orchestral\"\n",
      "        }, \n",
      "        {\n",
      "            \"count\": 1, \n",
      "            \"name\": \"british\"\n",
      "        }, \n",
      "        {\n",
      "            \"count\": 1, \n",
      "            \"name\": \"power pop\"\n",
      "        }, \n",
      "        {\n",
      "            \"count\": 1, \n",
      "            \"name\": \"psychedelic rock\"\n",
      "        }, \n",
      "        {\n",
      "            \"count\": 1, \n",
      "            \"name\": \"soft rock\"\n",
      "        }, \n",
      "        {\n",
      "            \"count\": 1, \n",
      "            \"name\": \"symphonic rock\"\n",
      "        }, \n",
      "        {\n",
      "            \"count\": 1, \n",
      "            \"name\": \"english\"\n",
      "        }\n",
      "    ], \n",
      "    \"type\": \"Group\"\n",
      "}\n",
      "requesting http://musicbrainz.org/ws/2/artist/9282c8b4-ca0b-4c6b-b7e3-4f7762dfc4d6?fmt=json&inc=releases\n",
      "\n",
      "ONE RELEASE:\n",
      "{\n",
      "  \"barcode\": null, \n",
      "  \"country\": \"GB\", \n",
      "  \"date\": \"1969\", \n",
      "  \"disambiguation\": \"\", \n",
      "  \"id\": \"0b44cb36-550a-491d-bfd9-8751271f9de7\", \n",
      "  \"packaging\": null, \n",
      "  \"packaging-id\": null, \n",
      "  \"quality\": \"normal\", \n",
      "  \"release-events\": [\n",
      "    {\n",
      "      \"area\": {\n",
      "        \"disambiguation\": \"\", \n",
      "        \"id\": \"8a754a16-0027-3a29-b6d7-2b40ea0481ed\", \n",
      "        \"iso-3166-1-codes\": [\n",
      "          \"GB\"\n",
      "        ], \n",
      "        \"name\": \"United Kingdom\", \n",
      "        \"sort-name\": \"United Kingdom\"\n",
      "      }, \n",
      "      \"date\": \"1969\"\n",
      "    }\n",
      "  ], \n",
      "  \"status\": \"Official\", \n",
      "  \"status-id\": \"4e304316-386d-3409-af2e-78857eec5cfe\", \n",
      "  \"text-representation\": {\n",
      "    \"language\": \"eng\", \n",
      "    \"script\": \"Latn\"\n",
      "  }, \n",
      "  \"title\": \"To Markos III\"\n",
      "}\n",
      "\n",
      "ALL TITLES:\n",
      "To Markos III\n",
      "Travelling on a Cloud\n",
      "Songs Of Love And Praise\n",
      "Songs of Love and Praise\n",
      "Songs of Love and Praise\n",
      "Secret Theatre\n",
      "The Story of Simon Simopath\n",
      "Me And My Friend\n",
      "All of Us\n",
      "The Story of Simon Simopath\n",
      "To Markos III\n",
      "Chemistry\n",
      "Local Anaesthetic\n",
      "Orange & Blue\n",
      "Pentecost Hotel\n",
      "Black Flower\n",
      "All of Us\n"
     ]
    }
   ],
   "source": [
    "json_play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18 - Exploring JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_group(artist):\n",
    "    return 'type' in artist and artist['type'].lower() == 'group'\n",
    "\n",
    "def has_same_name(artist, name):\n",
    "    return artist['name'].lower() == name.lower()\n",
    "\n",
    "def band_by_name(name):\n",
    "    results = query_by_name(ARTIST_URL, query_type[\"simple\"], name)\n",
    "    \n",
    "    return filter(lambda x: is_group(x) and has_same_name(x, name), results['artists'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3AFIRST+AID+KIT&fmt=json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of bands with the name\n",
    "len(band_by_name(\"FIRST AID KIT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3Aqueen&fmt=json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'London'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Name of Queen's begin area name\n",
    "band_by_name(\"queen\")[0]['begin-area']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3Athe+beatles&fmt=json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'Los Beatles'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Spanish alias for the beatles\n",
    "all_aliases = band_by_name('the beatles')[0]['aliases']\n",
    "filter(lambda x: x['locale'] == 'es', all_aliases)[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3Anirvana&fmt=json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'90s US grunge band'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#disambiguation for nirvana\n",
    "filter(lambda x: x['country'] == 'US',band_by_name('nirvana'))[0]['disambiguation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting http://musicbrainz.org/ws/2/artist/?query=artist%3Aone+direction&fmt=json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'2010-07'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#When was one direction formed?\n",
    "band_by_name('one direction')[0]['life-span']['begin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# Problem Set Starts here\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CSV\n",
    "\n",
    "Your task is to process the supplied file and use the csv module to extract data from it.\n",
    "The data comes from NREL (National Renewable Energy Laboratory) website. Each file\n",
    "contains information from one meteorological station, in particular - about amount of\n",
    "solar and wind energy for each hour of day.\n",
    "\n",
    "Note that the first line of the datafile is neither data entry, nor header. It is a line\n",
    "describing the data source. You should extract the name of the station from it.\n",
    "\n",
    "The data should be returned as a list of lists (not dictionaries).\n",
    "You can use the `csv` modules `reader` method to get data in such format.\n",
    "Another useful method is `next()` - to get the next line from the iterator.\n",
    "You should only change the parse_file function.\n",
    "\n",
    "### Resources\n",
    "Data comes from [NREL](http://www.nrel.gov/) website. The datafile in this exercise is a small subset from the full file for one of the stations. You can download it from the Downloadables section > or see the full data files for other stations on the [National Solar Radiation Data Base](http://rredc.nrel.gov/solar/old_data/nsrdb/1991-2005/tmy3/by_USAFN.html).\n",
    "\n",
    "[Documentation on csv.reader on docs.python.org](http://docs.python.org/2/library/csv.html#csv.reader)\n",
    "\n",
    "[Documentation on Reader object methods on docs.python.org](http://docs.python.org/2/library/csv.html#reader-objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "DATA_DIR = \"\"\n",
    "DATA_FILE = \"745090.csv\"\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "    name = \"\"\n",
    "    data = []\n",
    "    with open(datafile, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for i, row in enumerate(reader):\n",
    "            if i == 0:\n",
    "                name = row[1]\n",
    "            elif i == 1:\n",
    "                pass\n",
    "            else:\n",
    "                data.append(row)\n",
    "\n",
    "    # Do not change the line below\n",
    "    return name, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test1():\n",
    "    datafile = os.path.join(DATA_DIR, DATA_FILE)\n",
    "    name, data = parse_file(datafile)\n",
    "\n",
    "    assert name == \"MOUNTAIN VIEW MOFFETT FLD NAS\"\n",
    "    assert data[0][1] == \"01:00\"\n",
    "    assert data[2][0] == \"01/01/2005\"\n",
    "    assert data[2][5] == \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel to CSV\n",
    "\n",
    "Find the time and value of max load for each of the regions\n",
    "COAST, EAST, FAR_WEST, NORTH, NORTH_C, SOUTHERN, SOUTH_C, WEST\n",
    "and write the result out in a csv file, using pipe character | as the delimiter.\n",
    "\n",
    "An example output can be seen in the \"example.csv\" file.\n",
    "\n",
    "### Resources\n",
    "See csv module documentation on how to use different delimeters for csv.writer- http://docs.python.org/2/library/csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import os\n",
    "import csv\n",
    "\n",
    "DATA_FILE = \"2013_ERCOT_Hourly_Load_Data.xls\"\n",
    "OUT_FILE = \"2013_Max_Loads.csv\"\n",
    "\n",
    "def get_max_and_max_date_for_column(sheet, column_index):\n",
    "    data = data_for_column(sheet, column_index)\n",
    "    max_data = max(data)\n",
    "    date = get_date_for_row_containing_value(sheet, data, max_data)\n",
    "    return max_data, date\n",
    "\n",
    "\n",
    "def parse_file(datafile):\n",
    "\n",
    "    workbook = xlrd.open_workbook(datafile)\n",
    "    sheet = workbook.sheet_by_index(0)\n",
    "\n",
    "    return {\n",
    "        'COAST': get_max_and_max_date_for_column(sheet, 1),\n",
    "        'EAST': get_max_and_max_date_for_column(sheet, 2),\n",
    "        'FAR_WEST': get_max_and_max_date_for_column(sheet, 3),\n",
    "        'NORTH': get_max_and_max_date_for_column(sheet, 4),\n",
    "        'NORTH_C': get_max_and_max_date_for_column(sheet, 5),\n",
    "        'SOUTHERN': get_max_and_max_date_for_column(sheet, 6),\n",
    "        'SOUTH_C': get_max_and_max_date_for_column(sheet, 7),\n",
    "        'WEST': get_max_and_max_date_for_column(sheet, 8)\n",
    "    }\n",
    "\n",
    "\n",
    "def save_file(data, filename):\n",
    "    result = \"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        result += \"Station|Year|Month|Day|Hour|Max Load\\n\"\n",
    "        for key, value in data.iteritems():\n",
    "            result += \"{}|{}|{}|{}|{}|{}\\n\".format(\n",
    "                key, value[1][0], value[1][1], value[1][2], value[1][3], value[0])\n",
    "        result = result.strip(\"\\n\")\n",
    "\n",
    "        f.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test2():\n",
    "    # open_zip(DATA_FILE)\n",
    "    data = parse_file(DATA_FILE)\n",
    "    save_file(data, OUT_FILE)\n",
    "\n",
    "    number_of_rows = 0\n",
    "    stations = []\n",
    "\n",
    "    ans = {'FAR_WEST': {'Max Load': '2281.2722140000024',\n",
    "                        'Year': '2013',\n",
    "                        'Month': '6',\n",
    "                        'Day': '26',\n",
    "                        'Hour': '17'}}\n",
    "    correct_stations = ['COAST', 'EAST', 'FAR_WEST', 'NORTH',\n",
    "                        'NORTH_C', 'SOUTHERN', 'SOUTH_C', 'WEST']\n",
    "    fields = ['Year', 'Month', 'Day', 'Hour', 'Max Load']\n",
    "\n",
    "    with open(OUT_FILE) as of:\n",
    "        csvfile = csv.DictReader(of, delimiter=\"|\")\n",
    "        for line in csvfile:\n",
    "\n",
    "            station = line['Station']\n",
    "\n",
    "            if station == 'FAR_WEST':\n",
    "                for field in fields:\n",
    "                    # Check if 'Max Load' is within .1 of answer\n",
    "                    if field == 'Max Load':\n",
    "\n",
    "                        max_answer = round(float(ans[station][field]), 1)\n",
    "                        max_line = round(float(line[field]), 1)\n",
    "\n",
    "                        assert max_answer == max_line\n",
    "\n",
    "                    # Otherwise check for equality\n",
    "                    else:\n",
    "                        assert ans[station][field] == line[field]\n",
    "\n",
    "            number_of_rows += 1\n",
    "            stations.append(station)\n",
    "\n",
    "        # Output should be 8 lines not including header\n",
    "        assert number_of_rows == 8\n",
    "\n",
    "        # Check Station Names\n",
    "        assert set(stations) == set(correct_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling JSON\n",
    "\n",
    "This exercise shows some important concepts that you should be aware about:\n",
    "- using codecs module to write unicode files\n",
    "- using authentication with web APIs\n",
    "- using offset when accessing web APIs\n",
    "\n",
    "To run this code locally you have to register at the NYTimes developer site \n",
    "and get your own API key. You will be able to complete this exercise in our UI\n",
    "without doing so, as we have provided a sample result.\n",
    "\n",
    "Your task is to process the saved file that represents the most popular\n",
    "articles (by view count) from the last day, and return the following data:\n",
    "- list of dictionaries, where the dictionary key is \"section\" and value is \"title\"\n",
    "- list of URLs for all media entries with \"format\": \"Standard Thumbnail\"\n",
    "\n",
    "All your changes should be in the `article_overview` function.\n",
    "The rest of functions are provided for your convenience, if you want to access\n",
    "the API by yourself.\n",
    "\n",
    "If you want to know more, or query the site by yourself, please read the [NYTimes Developer Documentation for the Most Popular API](http://developer.nytimes.com/docs/most_popular_api/) and apply for your own [API Key for NY Times](http://developer.nytimes.com/page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "import requests\n",
    "\n",
    "URL_MAIN = \"http://api.nytimes.com/svc/\"\n",
    "URL_POPULAR = URL_MAIN + \"mostpopular/v2/\"\n",
    "API_KEY = { \"popular\": \"\",\n",
    "            \"article\": \"\"}\n",
    "\n",
    "\n",
    "def get_from_file(kind, period):\n",
    "    filename = \"popular-{0}-{1}.json\".format(kind, period)\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.loads(f.read())\n",
    "\n",
    "\n",
    "def article_overview(kind, period):\n",
    "    data = get_from_file(kind, period)\n",
    "    titles = []\n",
    "    urls = []\n",
    "    for row in data:\n",
    "        titles.append({row['section']: row['title']})\n",
    "        for media in row['media']:\n",
    "            for metadata in media['media-metadata']:\n",
    "                if metadata['format'] == 'Standard Thumbnail':\n",
    "                    urls.append(metadata['url'])\n",
    "\n",
    "    return titles, urls\n",
    "\n",
    "\n",
    "def query_site(url, target, offset):\n",
    "    # This will set up the query with the API key and offset\n",
    "    # Web services often use offset paramter to return data in small chunks\n",
    "    # NYTimes returns 20 articles per request, if you want the next 20\n",
    "    # You have to provide the offset parameter\n",
    "    if API_KEY[\"popular\"] == \"\" or API_KEY[\"article\"] == \"\":\n",
    "        print \"You need to register for NYTimes Developer account to run this program.\"\n",
    "        print \"See Intructor notes for information\"\n",
    "        return False\n",
    "    params = {\"api-key\": API_KEY[target], \"offset\": offset}\n",
    "    r = requests.get(url, params = params)\n",
    "\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        return r.json()\n",
    "    else:\n",
    "        r.raise_for_status()\n",
    "\n",
    "\n",
    "def get_popular(url, kind, days, section=\"all-sections\", offset=0):\n",
    "    # This function will construct the query according to the requirements of the site\n",
    "    # and return the data, or print an error message if called incorrectly\n",
    "    if days not in [1, 7, 30]:\n",
    "        print \"Time period can be 1,7, 30 days only\"\n",
    "        return False\n",
    "    if kind not in [\"viewed\", \"shared\", \"emailed\"]:\n",
    "        print \"kind can be only one of viewed/shared/emailed\"\n",
    "        return False\n",
    "\n",
    "    url += \"most{0}/{1}/{2}.json\".format(kind, section, days)\n",
    "    data = query_site(url, \"popular\", offset)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_file(kind, period):\n",
    "    # This will process all results, by calling the API repeatedly with supplied offset value,\n",
    "    # combine the data and then write all results in a file.\n",
    "    data = get_popular(URL_POPULAR, \"viewed\", 1)\n",
    "    num_results = data[\"num_results\"]\n",
    "    full_data = []\n",
    "    with codecs.open(\"popular-{0}-{1}.json\".format(kind, period), encoding='utf-8', mode='w') as v:\n",
    "        for offset in range(0, num_results, 20):\n",
    "            data = get_popular(URL_POPULAR, kind, period, offset=offset)\n",
    "            full_data += data[\"results\"]\n",
    "\n",
    "        v.write(json.dumps(full_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test3():\n",
    "    titles, urls = article_overview(\"viewed\", 1)\n",
    "    assert len(titles) == 20\n",
    "    assert len(urls) == 30\n",
    "    assert titles[2] == {'Opinion': 'Professors, We Need You!'}\n",
    "    assert urls[20] == 'http://graphics8.nytimes.com/images/2014/02/17/sports/ICEDANCE/ICEDANCE-thumbStandard.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test3()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
